{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaveshM.HW2-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnBHU-NA2mYH"
      },
      "source": [
        "# Assignment 2:  Minimax and Othello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDB4ow9x2lHq"
      },
      "source": [
        "In this assignment, you’ll program a minimax module for the board game Othello, also known as Reversi. The main module that you’ll program will calculate the value for a given board position. But, code is also provided for you that will let you play against your AI if you like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BURnh8rO27MS"
      },
      "source": [
        "The rules of Othello are as follows:\n",
        "\n",
        "1.   The two player colors are white and black. The white player goes first.\n",
        "2.   You capture an opponent’s pieces when they lie in a straight line between a piece you already had on the board and a piece you just played. (A straight line is left-right, up-down, or a 45 degree diagonal.)\n",
        "3.   You can only play a piece that would capture at least one piece. **If you have no legal moves, the turn is passed.**\n",
        "4.   The game is over when neither player has any legal moves left. Whoever controls the most pieces on the board at that point wins.\n",
        "\n",
        "Something that is slightly unusual about Othello for minimax is the fact that a turn might be skipped if a player has no legal plays. You’ll have to take that into account in your minimax calculations. (Don’t have skipped turns count against the search depth.)\n",
        "\n",
        "The AI is always presumed to be white for this assignment; if you try the demo mode, you as the human will be playing black.\n",
        "\n",
        "Similarly to the first assignment, we'll use a string representation of the board (W for white, B for black, - for an empty space)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmao2psX3nBB"
      },
      "source": [
        "**1)** Skim the provided functions below, then **implement minimax_value** including the search_depth limit, but not including alpha-beta pruning just yet.  The function should return WIN_VAL, -WIN_VAL, or 0 for a MAX win, MIN win, or tie respectively; and it should otherwise use the provided evaluation function that just counts piece difference.  You should be able to effectively use a depth of 5 or so without waiting too long."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEJqde0u4SOM"
      },
      "source": [
        "*Debugging tips:  While debugging, you’ll find it useful for minimax to print the board state it is evaluating and the value that it assigns to that board. Also, debug small depths before attempting larger ones.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Rm8Az02Pnr"
      },
      "source": [
        "\"\"\" Final code implements minimax with alpha-beta pruning for board game Othello.\"\"\"\n",
        "\n",
        "import copy\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "NUM_COLS = 8\n",
        "# With these constant values for players, flipping ownership is just a sign change\n",
        "WHITE = 1\n",
        "NOBODY = 0\n",
        "BLACK = -1\n",
        "\n",
        "TIE = 2  # NOT the value of a tie, which is 0 - just an arbitrary enum for end-of-game\n",
        "\n",
        "WIN_VAL = 100\n",
        "WHITE_TO_PLAY = True\n",
        "DEMO_SEARCH_DEPTH = 5\n",
        "\n",
        "# We'll sometimes iterate over this to look in all 8 directions from a particular square.\n",
        "# The values are the \"delta\" differences in row, col from the original square.\n",
        "# (Hence no (0,0), which would be the same square.)\n",
        "DIRECTIONS = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
        "\n",
        "\n",
        "def read_boardstring(boardstring):\n",
        "    \"\"\"Converts string representation of board to 2D numpy int array\"\"\"\n",
        "    board = np.zeros((NUM_COLS, NUM_COLS))\n",
        "    board_chars = {\n",
        "        'W': WHITE,\n",
        "        'B': BLACK,\n",
        "        '-': NOBODY\n",
        "    }\n",
        "    row = 0\n",
        "    for line in boardstring.splitlines():\n",
        "        for col in range(NUM_COLS):\n",
        "            board[row][col] = board_chars.get(line[col], NOBODY) # quietly ignore bad chars\n",
        "        row += 1\n",
        "    return board\n",
        "\n",
        "def find_winner(board):\n",
        "    \"\"\"Return identity of winner, assuming game is over.\n",
        "\n",
        "    Args:\n",
        "        board (numpy 2D int array):  The othello board, with WHITE/BLACK/NOBODY in spaces\n",
        "\n",
        "    Returns:\n",
        "        int constant:  WHITE, BLACK, or TIE.\n",
        "    \"\"\"\n",
        "    # Slick counting of values:  np.count_nonzero counts vals > 0, so pass in\n",
        "    # board == WHITE to get 1 or 0 in the right spots\n",
        "    white_count = np.count_nonzero(board == WHITE)\n",
        "    black_count = np.count_nonzero(board == BLACK)\n",
        "    if white_count > black_count:\n",
        "        return WHITE\n",
        "    if white_count < black_count:\n",
        "        return BLACK\n",
        "    return TIE\n",
        "\n",
        "def generate_legal_moves(board, white_turn):\n",
        "    \"\"\"Returns a list of (row, col) tuples representing places to move.\n",
        "\n",
        "    Args:\n",
        "        board (numpy 2D int array):  The othello board\n",
        "        white_turn (bool):  True if it's white's turn to play\n",
        "    \"\"\"\n",
        "\n",
        "    legal_moves = []\n",
        "    for row in range(NUM_COLS):\n",
        "        for col in range(NUM_COLS):\n",
        "            if board[row][col] != NOBODY:\n",
        "                continue   # Occupied, so not legal for a move\n",
        "            # Legal moves must capture something\n",
        "            if can_capture(board, row, col, white_turn):\n",
        "                legal_moves.append((row, col))\n",
        "    return legal_moves\n",
        "\n",
        "def can_capture(board, row, col, white_turn):\n",
        "    \"\"\" Helper that checks capture in each of 8 directions.\n",
        "\n",
        "    Args:\n",
        "        board (numpy 2D int array) - othello board\n",
        "        row (int) - row of move\n",
        "        col (int) - col of move\n",
        "        white_turn (bool) - True if it's white's turn\n",
        "    Returns:\n",
        "        True if capture is possible in any direction\n",
        "    \"\"\"\n",
        "    for r_delta, c_delta in DIRECTIONS:\n",
        "        if captures_in_dir(board, row, r_delta, col, c_delta, white_turn):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def captures_in_dir(board, row, row_delta, col, col_delta, white_turn):\n",
        "    \"\"\"Returns True iff capture possible in direction described by delta parameters\n",
        "\n",
        "    Args:\n",
        "        board (numpy 2D int array) - othello board\n",
        "        row (int) - row of original move\n",
        "        row_delta (int) - modification needed to row to move in direction of capture\n",
        "        col (int) - col of original move\n",
        "        col_delta (int) - modification needed to col to move in direction of capture\n",
        "        white_turn (bool) - True iff it's white's turn\n",
        "    \"\"\"\n",
        "\n",
        "    # Can't capture if headed off the board\n",
        "    if (row+row_delta < 0) or (row+row_delta >= NUM_COLS):\n",
        "        return False\n",
        "    if (col+col_delta < 0) or (col+col_delta >= NUM_COLS):\n",
        "        return False\n",
        "\n",
        "    # Can't capture if piece in that direction is not of appropriate color or missing\n",
        "    enemy_color = BLACK if white_turn else WHITE\n",
        "    if board[row+row_delta][col+col_delta] != enemy_color:\n",
        "        return False\n",
        "\n",
        "    # At least one enemy piece in this direction, so just need to scan until we\n",
        "    # find a friendly piece (return True) or hit an empty spot or edge of board\n",
        "    # (return False)\n",
        "    friendly_color = WHITE if white_turn else BLACK\n",
        "    scan_row = row + 2*row_delta # row of first scan position\n",
        "    scan_col = col + 2*col_delta # col of first scan position\n",
        "    while 0 <= scan_row < NUM_COLS and 0 <= scan_col < NUM_COLS:\n",
        "        if board[scan_row][scan_col] == NOBODY:\n",
        "            return False\n",
        "        if board[scan_row][scan_col] == friendly_color:\n",
        "            return True\n",
        "        scan_row += row_delta\n",
        "        scan_col += col_delta\n",
        "    return False\n",
        "\n",
        "def capture(board, row, col, white_turn):\n",
        "    \"\"\"Destructively change a board to represent capturing a piece with a move at (row,col).\n",
        "\n",
        "    The board's already a copy made specifically for the purpose of representing this move,\n",
        "    so there's no point in copying it again.  We'll return the board anyway.\n",
        "\n",
        "    Args:\n",
        "        board (numpy 2D int array) - The Othello board - will be destructively modified\n",
        "        row (int) - row of move\n",
        "        col (int) - col of move\n",
        "        white_turn (bool) - True iff it's white's turn\n",
        "    Returns:\n",
        "        The board, though this isn't necessary since it's destructively modified\n",
        "    \"\"\"\n",
        "\n",
        "    # Check in each direction as to whether flips can happen -- if they can, start flipping\n",
        "    enemy_color = BLACK if white_turn else WHITE\n",
        "    for row_delta, col_delta in DIRECTIONS:\n",
        "        if captures_in_dir(board, row, row_delta, col, col_delta, white_turn):\n",
        "            flip_row = row + row_delta\n",
        "            flip_col = col + col_delta\n",
        "            while board[flip_row][flip_col] == enemy_color:\n",
        "                board[flip_row][flip_col] = -enemy_color\n",
        "                flip_row += row_delta\n",
        "                flip_col += col_delta\n",
        "    return board\n",
        "\n",
        "def play_move(board, move, white_turn):\n",
        "    \"\"\"Handles the logic of putting down a new piece and flipping captured pieces.\n",
        "\n",
        "    The board that is returned is a copy, so this is appropriate to use for search.\n",
        "\n",
        "    Args:\n",
        "        board (numpy 2D int array):  The othello board\n",
        "        move ((int,int)):  A (row, col) pair for the move\n",
        "        white_turn:  True iff it's white's turn\n",
        "    Returns:\n",
        "        board (numpy 2D int array)\n",
        "    \"\"\"\n",
        "    new_board = copy.deepcopy(board)\n",
        "    new_board[move[0]][move[1]] = WHITE if white_turn else BLACK\n",
        "    new_board = capture(new_board, move[0], move[1], white_turn)\n",
        "    return new_board\n",
        "\n",
        "def evaluation_function(board):\n",
        "    \"\"\"Returns the difference in piece count - an easy evaluation function for minimax\"\"\"\n",
        "\n",
        "    # We could count with loops, but we're feeling fancy\n",
        "    return np.count_nonzero(board == WHITE) - np.count_nonzero(board == BLACK)\n",
        "\n",
        "def check_game_over(board):\n",
        "    \"\"\"Returns the current winner of the board - WHITE, BLACK, TIE, NOBODY\"\"\"\n",
        "\n",
        "    # It's not over if either player still has legal moves\n",
        "    white_legal_moves = generate_legal_moves(board, True)\n",
        "    if white_legal_moves:  # Python idiom for checking for empty list\n",
        "        return NOBODY\n",
        "    black_legal_moves = generate_legal_moves(board, False)\n",
        "    if black_legal_moves:\n",
        "        return NOBODY\n",
        "    # I guess the game's over\n",
        "    return find_winner(board)\n",
        "\n",
        "########################################### TODO\n",
        "def minimax_value(board, white_turn, search_depth, alpha, beta):\n",
        "    \"\"\"Return the value of the board, up to the maximum search depth.\n",
        "\n",
        "    Assumes white is MAX and black is MIN (even if black uses this function).\n",
        "\n",
        "    Args:\n",
        "        board (numpy 2D int array) - The othello board\n",
        "        white_turn (bool) - True iff white would get to play next on the given board\n",
        "        search_depth (int) - the search depth remaining, decremented for recursive calls\n",
        "        alpha (int or float) - Lower bound on the value:  MAX ancestor forbids lower results\n",
        "        beta (int or float) - Upper bound on the value:  MIN ancestor forbids larger results\n",
        "    \"\"\"\n",
        "    if check_game_over(board) != 0:\n",
        "      return {WHITE : WIN_VAL, BLACK : -1*WIN_VAL, TIE : 0}[check_game_over(board)]\n",
        "    if search_depth == 0:\n",
        "      return evaluation_function(board)\n",
        "    val = float('-inf') if white_turn else float('inf')\n",
        "    for m in generate_legal_moves(board, white_turn) if generate_legal_moves(board, white_turn) \\\n",
        "    else generate_legal_moves(board, not white_turn):\n",
        "      nb = play_move(board, m, white_turn)\n",
        "      func = max if white_turn else min\n",
        "      val = func(val, minimax_value(nb, not white_turn, search_depth - 1, alpha, beta))\n",
        "      if white_turn:\n",
        "        if val >= beta:\n",
        "          return val\n",
        "        alpha = max(val, alpha)\n",
        "      else:\n",
        "        if val <= alpha:\n",
        "          return val\n",
        "        beta = min(val, beta)\n",
        "    return val\n",
        "################################################################\n",
        "\n",
        "\n",
        "def print_board(board):\n",
        "    \"\"\" Print board (and return None), for interactive mode\"\"\"\n",
        "    printable = {\n",
        "        -1: \"B\",\n",
        "        0: \"-\",\n",
        "        1: \"W\"\n",
        "    }\n",
        "    for row in range(NUM_COLS):\n",
        "        line = \"\"\n",
        "        for col in range(NUM_COLS):\n",
        "            line += printable[board[row][col]]\n",
        "        print(line)\n",
        "\n",
        "def play():\n",
        "    \"\"\"Interactive play, for demo purposes.  Assume AI is white and goes first.\"\"\"\n",
        "    board = starting_board()\n",
        "    while check_game_over(board) == NOBODY:\n",
        "        # White turn (AI)\n",
        "        legal_moves = generate_legal_moves(board, True)\n",
        "        if legal_moves:  # (list is non-empty)\n",
        "            print(\"Thinking...\")\n",
        "            best_val = float(\"-inf\")\n",
        "            best_move = None\n",
        "            for move in legal_moves:\n",
        "                new_board = play_move(board, move, True)\n",
        "                move_val = minimax_value(new_board, True, DEMO_SEARCH_DEPTH, \\\n",
        "                                         float(\"-inf\"), float(\"inf\"))\n",
        "                if move_val > best_val:\n",
        "                    best_move = move\n",
        "                    best_val = move_val\n",
        "            board = play_move(board, best_move, True)\n",
        "            print_board(board)\n",
        "            print(\"\")\n",
        "        else:\n",
        "            print(\"White has no legal moves; skipping turn...\")\n",
        "\n",
        "        legal_moves = generate_legal_moves(board, False)\n",
        "        if legal_moves:\n",
        "            player_move = get_player_move(board, legal_moves)\n",
        "            board = play_move(board, player_move, False)\n",
        "            print_board(board)\n",
        "        else:\n",
        "            print(\"Black has no legal moves; skipping turn...\")\n",
        "    winner = find_winner(board)\n",
        "    if winner == WHITE:\n",
        "        print(\"White won!\")\n",
        "    elif winner == BLACK:\n",
        "        print(\"Black won!\")\n",
        "    else:\n",
        "        print(\"Tie!\")\n",
        "\n",
        "def starting_board():\n",
        "    \"\"\"Returns a board with the traditional starting positions in Othello.\"\"\"\n",
        "    board = np.zeros((NUM_COLS, NUM_COLS))\n",
        "    board[3][3] = WHITE\n",
        "    board[3][4] = BLACK\n",
        "    board[4][3] = BLACK\n",
        "    board[4][4] = WHITE\n",
        "    return board\n",
        "\n",
        "def get_player_move(board, legal_moves):\n",
        "    \"\"\"Print board with numbers for the legal move spaces, then get player choice of move\n",
        "\n",
        "    Args:\n",
        "        board (numpy 2D int array):  The Othello board.\n",
        "        legal_moves (list of (int,int)):  List of legal (row,col) moves for human player\n",
        "    Returns:\n",
        "        (int, int) representation of the human player's choice\n",
        "    \"\"\"\n",
        "    for row in range(NUM_COLS):\n",
        "        line = \"\"\n",
        "        for col in range(NUM_COLS):\n",
        "            if board[row][col] == WHITE:\n",
        "                line += \"W\"\n",
        "            elif board[row][col] == BLACK:\n",
        "                line += \"B\"\n",
        "            else:\n",
        "                if (row, col) in legal_moves:\n",
        "                    line += str(legal_moves.index((row, col)))\n",
        "                else:\n",
        "                    line += \"-\"\n",
        "        print(line)\n",
        "    while True:\n",
        "        # Bounce around this loop until a valid integer is received\n",
        "        choice = input(\"Which move do you want to play? [0-\" + str(len(legal_moves)-1) + \"]\")\n",
        "        try:\n",
        "            move_num = int(choice)\n",
        "            if 0 <= move_num < len(legal_moves):\n",
        "                return legal_moves[move_num]\n",
        "            print(\"That wasn't one of the options.\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter an integer as your move choice.\")\n",
        "\n",
        "def eval_at_depth(boardstring, depth):\n",
        "    \"\"\"Returns the value of the board up to the given search depth.\n",
        "\n",
        "    Args:\n",
        "        boardstring -- String representation of the board to evaluate.\n",
        "        depth --- Search depth limit.\n",
        "    \"\"\"\n",
        "    board = read_boardstring(boardstring)\n",
        "    return minimax_value(board, WHITE_TO_PLAY, depth, float(\"-inf\"), float(\"inf\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_kBB6IT4mtY"
      },
      "source": [
        "When you've completed your code, try running with the following boards and search depths.  The values should be 2,-3, and 1, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXjP81Of4xCi"
      },
      "source": [
        "clear_best_move = \"\"\"--------\n",
        "--------\n",
        "--B-----\n",
        "---BB---\n",
        "---BW---\n",
        "--------\n",
        "--------\n",
        "--------\"\"\"\n",
        "\n",
        "clear_best_countermove = \"\"\"--------\n",
        "--------\n",
        "--B-----\n",
        "---B----\n",
        "---BW---\n",
        "-----B--\n",
        "--------\n",
        "--------\"\"\"\n",
        "\n",
        "arbitrary_board = \"\"\"--------\n",
        "--------\n",
        "--------\n",
        "---WWW--\n",
        "---BW---\n",
        "BBBBB---\n",
        "--------\n",
        "--------\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP34FtUe5ROF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f0b70f-c4ce-4088-a080-8a011e7e4bdc"
      },
      "source": [
        "eval_at_depth(clear_best_move, 1) # Expect 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQotKCPk5aOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688e198f-6e80-437d-af64-86185c8f6f2b"
      },
      "source": [
        "eval_at_depth(clear_best_countermove, 2) # Expect -3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01B4MuVW5c1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42c27b0-69c3-43a4-c8ad-7b10ab1b5069"
      },
      "source": [
        "eval_at_depth(arbitrary_board, 5) # Expect 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muTyC-rC8F1c"
      },
      "source": [
        "Before implementing alpha-beta pruning, let's try a few conceptual questions to make sure we understand what's going on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDEh6PNt-ROh"
      },
      "source": [
        "**2) Explain in your own words:  why aren't alpha and beta values global to the whole tree, but instead copied and modified for each node?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnolPPtt-ij3"
      },
      "source": [
        "As the evaluation is Depth first, we keep track of updates in alpha and beta as we explore child nodes, as this update is reflected on the ancestor nodes and will be applied on parallel branches for pruning. The reason we are confident about alpha-beta is because the base node has been explored which would have updated the restrictions on what nodes should be explored, therefore increasing efficiency. It is a dynamic process and having global variables would be very inefficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaVVrDAn_2Oq"
      },
      "source": [
        "**3) Why does alpha-beta pruning always return the same values as not using it?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5LIA3ae__ty"
      },
      "source": [
        "This is because of the nature of MIN and MAX itself. MIN always chooses a child with the least value, therefore, it doesn't matter if MAX chooses a higher number--MIN simply wouldn't allow it and the answer would remain the same. This behavior applies to MAX as well. Having MIN explore branches after finding alpha or lower is futile as MAX would simply pick the alpha from somewhere else."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5o7hu_3_pF0"
      },
      "source": [
        "**4)** Now, **implement alpha-beta pruning** in the code above, and double-check that it gets the same results on the small search depths, but faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtuJPxihAPeC"
      },
      "source": [
        "You should now **evaluate the following board positions and depths**, which will be used in grading.  Notice that endgame will check your behavior when players don't have any moves, and also whether you're correctly returning win values - you may want to pay close attention to whether the results are reasonable there. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss0lq3aBAYod"
      },
      "source": [
        "some_board = \"\"\"--------\n",
        "--------\n",
        "--------\n",
        "---WB---\n",
        "---BW---\n",
        "--------\n",
        "--------\n",
        "--------\"\"\"\n",
        "\n",
        "endgame = \"\"\"WWWWBBBB\n",
        "WWWWBBBB\n",
        "WWWWBBBB\n",
        "BBBBBBBB\n",
        "BBBBBBBB\n",
        "BBBBBBBB\n",
        "BBBBBBBB\n",
        "--------\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uTEaPkoAm0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cca40fa-1ad4-4cb2-90a4-307faaea2e20"
      },
      "source": [
        "eval_at_depth(arbitrary_board, 8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gTnR9xmAqr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57b3c25-6051-4eeb-ce9a-0d415e62b407"
      },
      "source": [
        "eval_at_depth(some_board, 9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRYv4atLAtFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bbf3487-4818-480b-af22-fb6f90340426"
      },
      "source": [
        "eval_at_depth(endgame, 11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9we3m4OBkK1"
      },
      "source": [
        "If you want to play against your AI, you can in the next code window."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbm8E7N8CBOi"
      },
      "source": [
        "play()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct4fKAYKJpC7"
      },
      "source": [
        "Lastly, let's think about our evaluation function - counting pieces.  Experienced Othello players know that the corners are very valuable, because they're safe from attack and are good at capturing other pieces.  The edges might be considered also valuable, but not as much.\n",
        "\n",
        "Let's suppose we want the evaluation function to definitely be of the form $(w_1p_{max} + w_2e_{max} + w_3c_{max}) - (w_1p_{min} + w_2e_{min} + w_3c_{min})$, where $p$,$e$,and $c$ represent normal piece, edge, and corner counts for players $max$ or $min$.  (Every piece on the board belongs to exactly one of these categories.)  Our current evaluation function essentially sets $w_1 = w_2 = w_3 = 1$, but we could vary each weight individually to make positions more or less valuable.  We could use machine learning to adjust these weights, but we could also use another local search strategy, like hill climbing or genetic algorithms.\n",
        "\n",
        "**5)** Describe how beam search with k = 4 could find better weights $w_2$ and $w_3$ (we'll assume $w_1 = 1$).  Explain  a) what the \"neighbors\" of the present solution are, b) how to determine the \"fitness\" of a particular pair of weights, c) how the values to keep for the next generation or iteration are determined. Any reasonable implementation will get full credit; neighbor generation, for example, has a few reasonable approaches.  (If you want an opponent for your player, assume playing against a human is too slow, but a random-move player or another AI would be fine.  The weights don't need to be integers, but you could make the choice to limit the options to integers.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiZ6YBJORSLD"
      },
      "source": [
        "**TODO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-c1wuOtC54d"
      },
      "source": [
        "a. Heuristically speaking, since Corner pieces have a higher weightage, w3 can be higher than w2. from 1 and 1 we can go to having\n",
        "2, 4, 6, 8 for w2 and 4, 8, 12, 16 for w3. Their neighbors could range from +/- 0.4 which would be 1.8 1.9 2.1 2.2 for 2 in w2 and so on for all values.\n",
        "b. We can test how good it performs, we can have a fitness function that measures (negative of) time it takes to complete a certain evaluation problem \n",
        "(like the one given as an exercise, possible with many steps).\n",
        "c. Then out of the 16 values in the next generation, choose the best 4 values, i.e. with the highest fitness values (say, 2.1, 2.2, 3.8, 3.9 for w2) \n",
        "and generate neighbors of these values, possibly with a lower difference as time goes on. And when the fitness function seems to plateau, then \n",
        "you can be confident with your resultant weights."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLKhTmgIOxca"
      },
      "source": [
        "Turn in your .ipynb (Download as...) and .pdf (Print->Save as PDF) to Canvas.  Hey, you made a board game AI!"
      ]
    }
  ]
}